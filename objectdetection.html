<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width">
<title>Object Detection (coco-ssd) test</title>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"> </script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"> </script>
</head>

<body>
<h1>Object Detection (coco-ssd) test</h1>
<div class="container">
  <video id="videoElement" playsinline style="display:none"></video>
  <canvas id="canvasElement" width="1280px" height="720px"></canvas>
  <div class="landmark-grid-container"></div>
</div>
<label><input type="checkbox" id="showimg" checked>show original image</label>
<label><input type="checkbox" id="mirrormode">mirror mode</label>
<label><input type="checkbox" id="videomode" checked>video mode</label>
<input type="text" id="thrinp" value="0.66"> (threshold 0.0~1.0)
<hr>
APP: <a href="https://github.com/code4fukui/mediapipe-test/blob/main/objectdetection.html">Object Detection (coco-ssd) test - src on GitHub</a><br>
LIB: <a href="https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd">tfjs-models/coco-ssd at master · tensorflow/tfjs-models</a><br>
Blog: <a href=https://fukuno.jig.jp/3567>一日一創</a> by <a href=https://twitter.com/taisukef>@taisukef</a><br>
<style>
</style>

<script type="module">
import { Camera } from "https://code4fukui.github.io/Camera/Camera.js";
import { setDropImageFileListener } from "https://js.sabae.cc/setDropImageFileListener.js";

const g = canvasElement.getContext("2d");

const model = await cocoSsd.load();

const classes = [];

const draw = async (g, param) => {
  const predictions = await model.detect(param.image);
  const dw = param.w;
  const w = param.image.width || dw;
  const r = dw / w;

  const threathold = parseFloat(thrinp.value);
  for (const pred of predictions) {
    if (pred.score > threathold) {
      const p = document.createElement('p');
      const conf = Math.round(parseFloat(pred.score) * 100);
      const cls = pred.class;
      const n = (() => {
        const n = classes.indexOf(cls);
        if (n >= 0) {
          return n;
        }
        classes.push(cls);
        return classes.length;
      })();
      const txt = `${cls} ${conf}%`;
      const b = pred.bbox.map(d => d * r);
      //console.log(b);
      const color = `hsl(${360 / 10 * n},50%,50%)`;
      g.fillStyle = color;
      g.font = "20px serif";
      g.fillText(txt, b[0], b[1] - 5);
      g.strokeStyle = color;
      g.lineWidth = 4;
      g.strokeRect(b[0], b[1], b[2], b[3]);
    }
  }
};

const tick = async (image) => {
  const w = canvasElement.width;
  const h = canvasElement.height;
  g.save();
  if (mirrormode.checked) {
    g.scale(-1, 1);
    g.translate(-w, 0);
    /* // 180度回転
    g.translate(w / 2, h / 2);
    g.rotate(Math.PI);
    g.translate(-w / 2, -h / 2);
    */
  }
  g.clearRect(0, 0, w, h);
  if (showimg.checked) {
    const sw = image.width || w;
    const sh = image.height || h;
    const h2 = w / sw * sh;
    g.drawImage(image, 0, 0, sw, sh, 0, 0, w, h2);
  }

  g.globalCompositeOperation = 'source-over';
  await draw(g, { image, w });
  g.restore();
};

const camera = new Camera(videoElement, {
  onFrame: async () => {
    if (videomode.checked) {
      await tick(videoElement);
    }
  },
  width: 1280,
  height: 720,
});
camera.start();

setDropImageFileListener(document.body, async (img) => {
  videomode.checked = false;
  await tick(img);
});
</script>

</body>
</html>
