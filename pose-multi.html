<!DOCTYPE html><html lang="ja"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width"><link rel="icon" href="data:">

<!-- Mediapipe Pose -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
<link rel="stylesheet" href="style.css">

</head><body>

<body>
<h1>MediaPipe Pose + Coco-SSD test</h1>
<div class="container">
  <video id="videoElement" playsinline></video>
  <canvas id="canvasElement"></canvas>
  <div class="landmark-grid-container"></div>
</div>
<label><input type="checkbox" id="showimg">show original image</label>
<!--
<label><input type="checkbox" id="segimg">overwrite by segmentation</label>
-->
<label><input type="checkbox" id="mirrormode">mirror mode</label>
<label><input type="checkbox" id="backcameramode">backcamera mode</label>
<hr>
<footer>
<a href=./>demo index</a><br>
lib: <a href="https://chuoling.github.io/mediapipe/solutions/pose.html">Pose - mediapipe</a><br>
LIB: <a href="https://github.com/tensorflow/tfjs-models/tree/master/coco-ssd">tfjs-models/coco-ssd at master Â· tensorflow/tfjs-models</a><br>
src: <a href="https://github.com/code4fukui/mediapipe-test/">mediapipe-test</a><br>
</footer>


<script type="module">
import { Camera } from "https://code4fukui.github.io/Camera/Camera.js";
import { PoseMulti } from "./PoseMulti.js";

const g = canvasElement.getContext("2d");

const poseMulti = new PoseMulti();

poseMulti.setOptions({
  maxNumPoses: 5,
  staticImageMode: false,
  modelComplexity: 1,
  smoothLandmarks: true,
  enableSegmentation: false,
  smoothSegmentation: false,
  minDetectionConfidence: 0.5,
  minTrackingConfidence: 0.5
});


// Function to perform object detection and pose estimation
poseMulti.onResults(res => {
  const canvas = canvasElement;
  const video = videoElement;
  const w = canvasElement.width;
  const h = canvasElement.height;

  g.save();
  if (mirrormode.checked) {
    g.scale(-1, 1);
    g.translate(-w, 0);
  }
  g.clearRect(0, 0, w, h);
  if (showimg.checked) {
    g.drawImage(video, 0, 0, w, h);
  }
  
  // Function to draw pose landmarks
  function drawLandmarks(landmarks, offsetX, offsetY, width, height) {
    g.fillStyle = 'red';
    //g.lineWidth = 2;

    for (const landmark of landmarks) {
      const { x, y } = landmark;
      g.beginPath();
      g.arc(x * width + offsetX, y * height + offsetY, 5, 0, 2 * Math.PI);
      g.fill();
    }
  }
  g.scale(devicePixelRatio, devicePixelRatio);
  for (const person of res.people) {
    const [x, y, width, height ] = person.bbox;
    const poseLandmarks = person.poseLandmarks;

    // Draw bounding box
    g.strokeStyle = 'green';
    g.lineWidth = 2;
    g.strokeRect(x, y, width, height);
    g.fillStyle = 'green';
    g.fillText(`Person`, x, y - 5);

    drawLandmarks(poseLandmarks, x, y, width, height);
  }
  g.restore();
});

const camera = new Camera(videoElement, {
  onFrame: async () => {
    const dpi = devicePixelRatio;
    canvasElement.width = videoElement.videoWidth * dpi;
    canvasElement.height = videoElement.videoHeight * dpi;
    await poseMulti.send({ image: videoElement });
  },
  width: 1280,
  height: 720,
  backcamera: backcameramode.checked,
});
camera.start();
backcameramode.onchange = () => camera.flip();
</script>

</body></html>
